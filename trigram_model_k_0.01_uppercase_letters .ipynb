{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7245e97c",
   "metadata": {},
   "source": [
    "# Creation of a trigram model with a k-smoothing of 0.01 #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a038dd76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('treebank')\n",
    "from nltk.corpus import treebank\n",
    "from collections import defaultdict, Counter\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11e108f",
   "metadata": {},
   "source": [
    "### Print file length ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8897b639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files=treebank.fileids()\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a4efbe",
   "metadata": {},
   "source": [
    "### Print first sentence ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9afba57b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.'], ['Mr.', 'Vinken', 'is', 'chairman', 'of', 'Elsevier', 'N.V.', ',', 'the', 'Dutch', 'publishing', 'group', '.']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treebank.sents(files[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2155893e",
   "metadata": {},
   "source": [
    "### Split into training and test dataset ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b159dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = treebank.fileids()[:170]\n",
    "test_files = treebank.fileids()[170:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b47f18",
   "metadata": {},
   "source": [
    "### Making sure that they are the correct length ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8a18e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "print(len(train_files))\n",
    "print(len(test_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ebe7c3",
   "metadata": {},
   "source": [
    "### If word count in vocabulary <3 change with \\<UNK> ###\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "298afc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_counter = Counter()\n",
    "\n",
    "for file in train_files:\n",
    "    for sent in treebank.sents(file):\n",
    "        token_counter.update([token for token in sent])\n",
    "\n",
    "unk_token = \"<UNK>\"\n",
    "vocab = {token for token, count in token_counter.items() if count >= 3}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3f5a45",
   "metadata": {},
   "source": [
    "### Creates a list of trigrams with boundary markers from sentences in training files ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a5d5be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trigrams = []\n",
    "for file in train_files:\n",
    "    for sent in treebank.sents(file):\n",
    "        sent = ['<BOS>'] + [token if token in vocab else unk_token for token in sent] + ['<EOS>']\n",
    "        train_trigrams.extend(nltk.trigrams(sent))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821a1a4d",
   "metadata": {},
   "source": [
    "### Computing smoothed trigram probabilities  ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24c59f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=0.01\n",
    "# Count trigrams in the training data\n",
    "trigram_counts = defaultdict(Counter)\n",
    "for trigram in train_trigrams:\n",
    "    trigram_counts[trigram[:-1]][trigram[-1]] += 1\n",
    "\n",
    "# Calculate smoothed probabilities for trigrams\n",
    "trigram_smoothed_probs = defaultdict(Counter)\n",
    "for w1_w2 in trigram_counts:\n",
    "    total_count = sum(trigram_counts[w1_w2].values()) + k * len(vocab)\n",
    "    for w3 in trigram_counts[w1_w2]:\n",
    "        trigram_smoothed_probs[w1_w2][w3] = (trigram_counts[w1_w2][w3] + k) / total_count\n",
    "\n",
    "test_trigrams = []\n",
    "test_trigram_count = 0\n",
    "for file in test_files:\n",
    "    for sent in treebank.sents(file):\n",
    "        sent = ['<BOS>'] + [token if token in vocab else unk_token for token in sent] + ['<EOS>']\n",
    "        test_trigrams.extend(nltk.trigrams(sent))\n",
    "        test_trigram_count += len(sent) \n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468ca8a7",
   "metadata": {},
   "source": [
    "### Evaluating sum of ln prob ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d71cc39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ln_prob_sum = 0.0\n",
    "for trigram in test_trigrams:\n",
    "    w1, w2, w3 = trigram\n",
    "    prob = trigram_smoothed_probs[(w1, w2)][w3] if w3 in trigram_smoothed_probs[(w1, w2)] else (k / (sum(trigram_counts[(w1, w2)].values()) + k * len(vocab)))\n",
    "    \n",
    "    ln_prob_sum += math.log(prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2e2a43",
   "metadata": {},
   "source": [
    "### Print perplexity ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41b82f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294.44845074773707\n"
     ]
    }
   ],
   "source": [
    "perplexity = math.exp(-1 * (ln_prob_sum / test_trigram_count))\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5149ac",
   "metadata": {},
   "source": [
    "### Function to generate sentences based on starting word of the model checking start with \\<BOS > ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "599ad52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(test_trigrams, trigram_smoothed_probs, start_word,  unk_token='<UNK>'):\n",
    "    generated_sentence = ['<BOS>', start_word]\n",
    "    while generated_sentence[-1] != '<EOS>':\n",
    "        w1, w2 = generated_sentence[-2], generated_sentence[-1]\n",
    "        next_word_candidates = list(trigram_smoothed_probs[(w1, w2)].keys())\n",
    "        next_word_candidates = [word for word in next_word_candidates if word != unk_token]  # Filter out <unk> token\n",
    "        \n",
    "        if next_word_candidates:\n",
    "            next_word_probs = [trigram_smoothed_probs[(w1, w2)][word] for word in next_word_candidates]\n",
    "            next_word = random.choices(next_word_candidates, weights=next_word_probs)[0]\n",
    "        else:\n",
    "            break  \n",
    "        \n",
    "        generated_sentence.append(next_word)\n",
    "    \n",
    "    if generated_sentence[-1] == '<EOS>':\n",
    "        generated_sentence.pop()  # Remove <EOS>\n",
    "    \n",
    "    return generated_sentence[1:]  # Remove <BOS> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb571165",
   "metadata": {},
   "source": [
    "### Generate the sentences with starting words 'If', 'An, 'For' ###\n",
    "\n",
    "The generated sentences are better than bigram sentences,although not satisfying at all, but the trigram does not always find a possible next canditate so the use of break is needed to not create an infinite loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6531acc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If , when terms are scheduled *-3 to cover all transaction costs .\n",
      "An appeal is expected *-4 to be sold *-1 at $ 90 *U* a share , compared with $ 6 million *U* in 1990 .\n",
      "For their part , this exclusive club has taken measures *-1 to accommodate Japanese business interests -LCB- in the fiscal year ending June 30 , 1990 .\n"
     ]
    }
   ],
   "source": [
    "start_words = ['If', 'An', 'For']\n",
    "generated_sentences = []\n",
    "\n",
    "for start_word in start_words:\n",
    "    generated_sentence = generate_sentence(test_trigrams, trigram_smoothed_probs, start_word)\n",
    "    generated_sentences.append(generated_sentence)\n",
    "    print(' '.join(generated_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5fde92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
