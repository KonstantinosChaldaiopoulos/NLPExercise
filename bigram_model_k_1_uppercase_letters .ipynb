{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab5c968c",
   "metadata": {},
   "source": [
    "# Creation of a bigram model with a k-smoothing of 0.1 #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a038dd76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('treebank')\n",
    "from nltk.corpus import treebank\n",
    "from collections import defaultdict, Counter\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80776fd4",
   "metadata": {},
   "source": [
    "### Print file length ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8897b639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files=treebank.fileids()\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a22eecd",
   "metadata": {},
   "source": [
    "### Print first sentence ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9afba57b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.'], ['Mr.', 'Vinken', 'is', 'chairman', 'of', 'Elsevier', 'N.V.', ',', 'the', 'Dutch', 'publishing', 'group', '.']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treebank.sents(files[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81b4e7a",
   "metadata": {},
   "source": [
    "### Split into training and test dataset ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b159dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = treebank.fileids()[:170]\n",
    "test_files = treebank.fileids()[170:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3982aa",
   "metadata": {},
   "source": [
    "### Making sure that they are the correct length ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8a18e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "print(len(train_files))\n",
    "print(len(test_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe9d653",
   "metadata": {},
   "source": [
    "### If word count in vocabulary <3 change with \\<UNK> ###\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73ca2710",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_counter = Counter()\n",
    "for file in train_files:\n",
    "    for sent in treebank.sents(file):\n",
    "        token_counter.update([token for token in sent])\n",
    "\n",
    "unk_token = \"<UNK>\"\n",
    "vocab = {token for token, count in token_counter.items() if count >= 3}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b06a1a",
   "metadata": {},
   "source": [
    "###  Creates bigrams using \\<BOS> and \\<EOS> to ensure correct bigram creation ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a5d5be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bigrams = []\n",
    "for file in train_files:\n",
    "    for sent in treebank.sents(file):\n",
    "        sent = ['<BOS>'] + [token if token in vocab else unk_token for token in sent] + ['<EOS>']\n",
    "        train_bigrams.extend(nltk.bigrams(sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde651c5",
   "metadata": {},
   "source": [
    "### Bigram Language Model with Add-k Smoothing  ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24c59f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1\n",
    "bigram_counts = defaultdict(Counter)\n",
    "for bigram in train_bigrams:\n",
    "    bigram_counts[bigram[0]][bigram[1]] += 1\n",
    "\n",
    "bigram_smoothed_probs = defaultdict(Counter)\n",
    "for w1 in bigram_counts:\n",
    "    total_count = sum(bigram_counts[w1].values()) + k * len(vocab)\n",
    "    for w2 in bigram_counts[w1]:\n",
    "        bigram_smoothed_probs[w1][w2] = (bigram_counts[w1][w2] + k) / total_count\n",
    "        \n",
    "test_bigrams = []\n",
    "test_bigram_count = 0\n",
    "for file in test_files:\n",
    "    for sent in treebank.sents(file):\n",
    "        sent = ['<BOS>'] + [token if token in vocab else unk_token for token in sent] + ['<EOS>']\n",
    "        test_bigrams.extend(nltk.bigrams(sent))\n",
    "        test_bigram_count += len(sent) \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d59119",
   "metadata": {},
   "source": [
    "### Evaluating test data log probability ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c3e218e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ln_prob_sum = 0.0\n",
    "for bigram in test_bigrams:\n",
    "    w1, w2 = bigram\n",
    "    prob = bigram_smoothed_probs[w1][w2] if w2 in bigram_smoothed_probs[w1] else (k / (sum(bigram_counts[w1].values()) + k * len(vocab)))\n",
    "    ln_prob_sum += math.log(prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3073b4",
   "metadata": {},
   "source": [
    "### Print perplexity ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0965a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307.7242557108501\n"
     ]
    }
   ],
   "source": [
    "perplexity = math.exp(-1 * (ln_prob_sum / test_bigram_count))\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736c7a2f",
   "metadata": {},
   "source": [
    "### Function to generate sentences based on starting word of the model checking start with \\<BOS > ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "599ad52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(test_bigrams, bigram_model, start_word):\n",
    "    if ('<BOS>', start_word) not in [(bigram[0], bigram[1]) for bigram in test_bigrams if bigram[0] == '<BOS>']:\n",
    "        raise ValueError(\"The provided start_word should be the second word of a bigram where the first word is '<BOS>' in the bigram model.\")\n",
    "    \n",
    "    sentence = [start_word]\n",
    "    while sentence[-1] != '<EOS>':\n",
    "        next_word_candidates = list(bigram_model[sentence[-1]].keys())\n",
    "        next_word_probs = list(bigram_model[sentence[-1]].values())\n",
    "        next_word = random.choices(next_word_candidates, next_word_probs)[0]\n",
    "        \n",
    "        if next_word == '<UNK>':\n",
    "            continue\n",
    "        \n",
    "        sentence.append(next_word)\n",
    "    \n",
    "    return sentence[:-1] # exclude <EOS>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd45782",
   "metadata": {},
   "source": [
    "### Generate the sentences with starting words 'If', 'An, 'For' ###\n",
    "\n",
    "The sentences do not appear to convey any meaningful information or follow a coherent narrative or theme. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6531acc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If those returns are in their stock when the prospects .\n",
      "An equal fiscal 1990 would result , Wall Street , says *T*-1 * to be able *-1 with its own tax .\n",
      "For the Old Guard -- even in Article II '' Chaplin 's and the Foreign Ministry official at $ 75 million *U* -RRB- in question now , construction , also could get *T*-1 ? '' said 0 *T*-1 open a default to a great purpose , to compromise measure the banks said 0 he 's car purchase grain supply of specialty retail or history , a mental illness or at Greenville in intellectual-property rights of small American member of a recent example , regulatory capital .\n"
     ]
    }
   ],
   "source": [
    "start_words = ['If', 'An', 'For']\n",
    "generated_sentences = []\n",
    "\n",
    "for start_word in start_words:\n",
    "    generated_sentence = generate_sentence(test_bigrams,bigram_smoothed_probs, start_word)\n",
    "    generated_sentences.append(generated_sentence)\n",
    "    print(' '.join(generated_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d11702",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
