{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7245e97c",
   "metadata": {},
   "source": [
    "# Creation of a bigram model with a k-smoothing of 0.01 #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a038dd76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('treebank')\n",
    "from nltk.corpus import treebank\n",
    "from collections import defaultdict, Counter\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11e108f",
   "metadata": {},
   "source": [
    "### Print file length ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8897b639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files=treebank.fileids()\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a4efbe",
   "metadata": {},
   "source": [
    "### Print first sentence ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9afba57b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.'], ['Mr.', 'Vinken', 'is', 'chairman', 'of', 'Elsevier', 'N.V.', ',', 'the', 'Dutch', 'publishing', 'group', '.']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treebank.sents(files[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2155893e",
   "metadata": {},
   "source": [
    "### Split into training and test dataset ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b159dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = treebank.fileids()[:170]\n",
    "test_files = treebank.fileids()[170:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b47f18",
   "metadata": {},
   "source": [
    "### Making sure that they are the correct length ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8a18e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "print(len(train_files))\n",
    "print(len(test_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ebe7c3",
   "metadata": {},
   "source": [
    "### Create a vocab for words >3 ###\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "298afc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_counter = Counter()\n",
    "\n",
    "for file in train_files:\n",
    "    for sent in treebank.sents(file):\n",
    "        token_counter.update([token for token in sent])\n",
    "\n",
    "unk_token = \"<UNK>\"\n",
    "vocab = {token for token, count in token_counter.items() if count >= 3}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3f5a45",
   "metadata": {},
   "source": [
    "### Creates bigrams using \\<BOS> and \\<EOS> to ensure correct bigram creation ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a5d5be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bigrams = []\n",
    "for file in train_files:\n",
    "    for sent in treebank.sents(file):\n",
    "        sent = ['<BOS>'] + [token if token in vocab else unk_token for token in sent] + ['<EOS>']\n",
    "        train_bigrams.extend(nltk.bigrams(sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821a1a4d",
   "metadata": {},
   "source": [
    "### Bigram Language Model with Add-k Smoothing  ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24c59f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0.01\n",
    "bigram_counts = defaultdict(Counter)\n",
    "for bigram in train_bigrams:\n",
    "    bigram_counts[bigram[0]][bigram[1]] += 1\n",
    "    \n",
    "\n",
    "\n",
    "bigram_smoothed_probs = defaultdict(Counter)\n",
    "for w1 in bigram_counts:\n",
    "    total_count = sum(bigram_counts[w1].values()) + k * len(vocab)\n",
    "    for w2 in bigram_counts[w1]:\n",
    "        bigram_smoothed_probs[w1][w2] = (bigram_counts[w1][w2] + k ) / total_count\n",
    "\n",
    "\n",
    "        \n",
    "test_bigrams = []\n",
    "test_bigram_count = 0\n",
    "for file in test_files:\n",
    "    for sent in treebank.sents(file):\n",
    "        sent = ['<BOS>'] + [token if token in vocab else unk_token for token in sent] + ['<EOS>'] # Replace with UNK also\n",
    "        test_bigrams.extend(nltk.bigrams(sent))\n",
    "        test_bigram_count += len(sent)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468ca8a7",
   "metadata": {},
   "source": [
    "### Evaluating sum of ln prob ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d71cc39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_prob_sum = 0.0        \n",
    "ln_prob_sum = 0.0\n",
    "\n",
    "for bigram in test_bigrams:\n",
    "    w1, w2 = bigram\n",
    "    if w1 in bigram_smoothed_probs and w2 in bigram_smoothed_probs[w1]:\n",
    "        prob = bigram_smoothed_probs[w1][w2]\n",
    "    else:\n",
    "        bigram_count = bigram_counts.get((w1, w2), 0)\n",
    "        prob = (bigram_count + k) / (sum(bigram_counts[w1].values()) + k * len(bigram_counts[w1]))\n",
    "    ln_prob_sum += math.log(prob)\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2e2a43",
   "metadata": {},
   "source": [
    "### Print perplexity ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41b82f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.09626625932748\n"
     ]
    }
   ],
   "source": [
    "perplexity = math.exp(-1 * (ln_prob_sum / test_bigram_count))\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5149ac",
   "metadata": {},
   "source": [
    "### Function to generate sentences based on starting word of the model checking start with \\<BOS > ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "599ad52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(test_bigrams, bigram_model, start_word):\n",
    "    if ('<BOS>', start_word) not in [(bigram[0], bigram[1]) for bigram in test_bigrams if bigram[0] == '<BOS>']:\n",
    "        raise ValueError(\"The provided start_word should be the second word of a bigram where the first word is '<BOS>' in the bigram model.\")\n",
    "    \n",
    "    sentence = [start_word]\n",
    "    while sentence[-1] != '<EOS>':\n",
    "        next_word_candidates = list(bigram_model[sentence[-1]].keys())\n",
    "        next_word_probs = list(bigram_model[sentence[-1]].values())\n",
    "        next_word = random.choices(next_word_candidates, next_word_probs)[0]\n",
    "        \n",
    "        if next_word == '<UNK>':\n",
    "            continue\n",
    "        \n",
    "        sentence.append(next_word)\n",
    "    \n",
    "    return sentence[:-1] # exclude <EOS>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb571165",
   "metadata": {},
   "source": [
    "### Generate the sentences with starting words 'If', 'An, 'For' ###\n",
    "\n",
    "The sentences do not appear to convey any meaningful information or follow a coherent narrative or theme. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6531acc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If not feel 0 the guards there has been tendered *-1 by up *T*-1 went to $ 20 % from above 50 3\\/8 % .\n",
      "An official who *T*-5 ? '' and not effective Dec. 21 % of units of the issue was a number and freedom and 1972 -- a share .\n",
      "The Senate Foreign Ministry had *?* .\n"
     ]
    }
   ],
   "source": [
    "start_words = ['If', 'An', 'The']\n",
    "generated_sentences = []\n",
    "\n",
    "for start_word in start_words:\n",
    "    generated_sentence = generate_sentence(test_bigrams, bigram_smoothed_probs, start_word)\n",
    "    generated_sentences.append(generated_sentence)\n",
    "    print(' '.join(generated_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffda1f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
